{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Feature Pipeline Notebook\n",
    "\n",
    "This notebook processes demand data and uploads it to the Hopsworks feature store. It replicates the functionality of the feature_pipeline.py script in an interactive format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "We'll load environment variables for Hopsworks connection credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure parameters (these can be modified as needed)\n",
    "project_name = 'many_models'\n",
    "feature_group_name = 'demand_features'\n",
    "version = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks Feature Store\n",
    "\n",
    "Establish connection to the Hopsworks Feature Store using credentials from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connecting to Hopsworks Feature Store\")\n",
    "\n",
    "# Connect to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    host=os.getenv(\"HOST\"),\n",
    "    port=os.getenv(\"PORT\"),\n",
    "    api_key_value=os.getenv(\"HOPSWORKS_API_KEY\"),\n",
    "    project=project_name or os.getenv(\"PROJECT\")\n",
    ")\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "print(f\"Connected to feature store in project: {project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Source Data\n",
    "\n",
    "Load the demand data from CSV file and prepare it for the feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading source data\")\n",
    "demand_df = pd.read_csv('../data/demand_qty_item_loc.csv')\n",
    "\n",
    "# Display first few rows to inspect the data\n",
    "display(demand_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column headers to match the data model\n",
    "demand_df.columns = ['sp_id', 'loc_id', 'time_bucket', 'repetitive_demand_quantity']\n",
    "\n",
    "# Add datetime column for feature store\n",
    "demand_df['datetime'] = datetime.now()\n",
    "\n",
    "# Display the transformed dataframe\n",
    "display(demand_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data Dimensions\n",
    "\n",
    "Explore the dimensionality of our demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data dimensions\n",
    "unique_items = demand_df['sp_id'].nunique()\n",
    "unique_locations = demand_df['loc_id'].nunique()\n",
    "unique_time_periods = demand_df['time_bucket'].nunique()\n",
    "\n",
    "print(f\"ðŸš€ Found {unique_items} items Ã— {unique_locations} locations Ã— {unique_time_periods} time periods\")\n",
    "\n",
    "# Optional: Create a more detailed summary\n",
    "summary = {\n",
    "    \"Items\": unique_items,\n",
    "    \"Locations\": unique_locations, \n",
    "    \"Time Periods\": unique_time_periods,\n",
    "    \"Total Records\": len(demand_df)\n",
    "}\n",
    "pd.DataFrame([summary]).T.rename(columns={0: \"Count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Group and Upload Data\n",
    "\n",
    "Define the feature group schema and upload the prepared data to the feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â¬† Creating/getting feature group\")\n",
    "# Define the feature group\n",
    "demand_fg = fs.get_or_create_feature_group(\n",
    "    name=feature_group_name,\n",
    "#    version=version, # Uncomment if you want to specify a version else it will be auto-incremented\n",
    "    description=\"Item demand by location and time\",\n",
    "    primary_key=['sp_id', 'loc_id', 'time_bucket'],\n",
    "    event_time='datetime',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â¬† Uploading data to the Feature Store\")\n",
    "# Upload data to the feature store\n",
    "demand_fg.insert(demand_df, write_options={\"wait_for_job\": True})\n",
    "print(\"Feature pipeline completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Feature Group \n",
    "\n",
    "Retrieve and inspect the feature group schema and data to verify successful upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature descriptions\n",
    "print(\"Feature Group Schema:\")\n",
    "display(demand_fg.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data from the feature group\n",
    "print(\"Sample Data from Feature Group:\")\n",
    "sample_data = demand_fg.read()\n",
    "display(sample_data.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
